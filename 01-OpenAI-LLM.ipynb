{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c08e74",
   "metadata": {},
   "source": [
    "## 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387d4e6-6730-4b0c-be03-110d5914c2b8",
   "metadata": {},
   "source": [
    "### 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e309c0da-4769-406b-89c4-465eaa7ae4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b5749",
   "metadata": {},
   "source": [
    "`OPENAI_API_KEY` 에 발급받은 API KEY 를 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9b6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'OPENAI API KEY 입력'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 정보로드를 위한 라이브러리\n",
    "# 설치: pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 토큰 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad64364",
   "metadata": {},
   "source": [
    "사용 가능한 모델 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac635a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada\n",
      "ada-code-search-code\n",
      "ada-code-search-text\n",
      "ada-search-document\n",
      "ada-search-query\n",
      "ada-similarity\n",
      "babbage\n",
      "babbage-002\n",
      "babbage-code-search-code\n",
      "babbage-code-search-text\n",
      "babbage-search-document\n",
      "babbage-search-query\n",
      "babbage-similarity\n",
      "code-davinci-edit-001\n",
      "code-search-ada-code-001\n",
      "code-search-ada-text-001\n",
      "code-search-babbage-code-001\n",
      "code-search-babbage-text-001\n",
      "curie\n",
      "curie-instruct-beta\n",
      "curie-search-document\n",
      "curie-search-query\n",
      "curie-similarity\n",
      "davinci\n",
      "davinci-002\n",
      "davinci-instruct-beta\n",
      "davinci-search-document\n",
      "davinci-search-query\n",
      "davinci-similarity\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0314\n",
      "gpt-4-0613\n",
      "text-ada-001\n",
      "text-babbage-001\n",
      "text-curie-001\n",
      "text-davinci-001\n",
      "text-davinci-002\n",
      "text-davinci-003\n",
      "text-davinci-edit-001\n",
      "text-embedding-ada-002\n",
      "text-search-ada-doc-001\n",
      "text-search-ada-query-001\n",
      "text-search-babbage-doc-001\n",
      "text-search-babbage-query-001\n",
      "text-search-curie-doc-001\n",
      "text-search-curie-query-001\n",
      "text-search-davinci-doc-001\n",
      "text-search-davinci-query-001\n",
      "text-similarity-ada-001\n",
      "text-similarity-babbage-001\n",
      "text-similarity-curie-001\n",
      "text-similarity-davinci-001\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "model_list = sorted([m['id'] for m in openai.Model.list()['data']])\n",
    "for m in model_list:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## ChatOpenAI\n",
    "\n",
    "OpenAI 사의 채팅 전용 Large Language Model(llm) 입니다. \n",
    "\n",
    "객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\n",
    "\n",
    "`temperature`\n",
    "- 사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\n",
    "\n",
    "`max_tokens`\n",
    "- 채팅 완성에서 생성할 토큰의 최대 개수입니다. \n",
    "\n",
    "`model_name`: 적용 가능한 모델 리스트\n",
    "- gpt-3.5-turbo\n",
    "- gpt-3.5-turbo-0301\n",
    "- gpt-3.5-turbo-0613\n",
    "- gpt-3.5-turbo-16k\n",
    "- gpt-3.5-turbo-16k-0613\n",
    "- gpt-3.5-turbo-instruct\n",
    "- gpt-3.5-turbo-instruct-0914\n",
    "- gpt-4\n",
    "- gpt-4-0314\n",
    "- gpt-4-0613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc161c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: 대한민국의 수도는 서울입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \n",
    "                 max_tokens=2048,             # 최대 토큰수\n",
    "                 model_name='gpt-3.5-turbo',  # 모델명\n",
    "                )\n",
    "\n",
    "# 질의내용\n",
    "question = '대한민국의 수도는 뭐야?'\n",
    "\n",
    "# 질의\n",
    "print(f'[답변]: {llm.predict(question)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d74d9",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8aedc",
   "metadata": {},
   "source": [
    "`PromptTemplate`\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\n",
    "- 사용법\n",
    "  - `template`: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 `{}`는 변수를 나타냅니다.\n",
    "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "\n",
    "`input_variables`\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\n",
    "- 사용법: 리스트 형식으로 변수 이름을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3f01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = '{country}의 수도는 뭐야?'\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(template=template, input_variables=['country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d700a6e",
   "metadata": {},
   "source": [
    "### LLMChain 객체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cc045",
   "metadata": {},
   "source": [
    "`LLMChain`\n",
    "- LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\n",
    "- 사용법\n",
    "  - `prompt`: 앞서 정의한 PromptTemplate 객체를 사용합니다.\n",
    "  - `llm`: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572eb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98f9d8",
   "metadata": {},
   "source": [
    "### run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff17ad",
   "metadata": {},
   "source": [
    "`run()` 함수로 템플릿 프롬프트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ddbf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일본의 수도는 도쿄입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행: run() \n",
    "print(llm_chain.run(country='일본'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9269fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐나다의 수도는 오타와(Ottawa)입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행: run() \n",
    "print(llm_chain.run(country='캐나다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9a157",
   "metadata": {},
   "source": [
    "### apply()\n",
    "\n",
    "`apply()` 함수로 여러개의 입력을 한 번에 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b656d241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '호주의 수도는 캔버라입니다.'},\n",
       " {'text': '중국의 수도는 베이징(北京)입니다.'},\n",
       " {'text': '네덜란드의 수도는 암스테르담(Amsterdam)입니다.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'country': '호주'},\n",
    "    {'country': '중국'},\n",
    "    {'country': '네덜란드'}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622efee7",
   "metadata": {},
   "source": [
    "`text` 키 값으로 결과 뭉치가 반환되었음을 확인할 수 있습니다.\n",
    "\n",
    "이를 반복문으로 출력한다면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01abd39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호주의 수도는 캔버라입니다.\n",
      "중국의 수도는 베이징(北京)입니다.\n",
      "네덜란드의 수도는 암스테르담(Amsterdam)입니다.\n"
     ]
    }
   ],
   "source": [
    "# input_list 에 대한 결과 반환\n",
    "result = llm_chain.apply(input_list)\n",
    "\n",
    "# 반복문으로 결과 출력\n",
    "for res in result:\n",
    "    print(res['text'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38852a",
   "metadata": {},
   "source": [
    "### `generate()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd758206",
   "metadata": {},
   "source": [
    "`generate()` 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다. \n",
    "\n",
    "LLMResult는 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2457653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\n"
     ]
    }
   ],
   "source": [
    "# input_list 에 대한 결과 반환\n",
    "generated_result = llm_chain.generate(input_list)\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3034ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))],\n",
       " [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))],\n",
       " [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 답변 출력\n",
    "generated_result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59487318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 58,\n",
       "  'completion_tokens': 57,\n",
       "  'total_tokens': 115},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 사용량 출력\n",
    "generated_result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe647a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\n",
       " RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\n",
       " RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run ID 출력\n",
    "generated_result.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "810633c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호주의 수도는 캔버라입니다.\n",
      "중국의 수도는 베이징(北京)입니다.\n",
      "네덜란드의 수도는 암스테르담(Amsterdam)입니다.\n"
     ]
    }
   ],
   "source": [
    "# 답변 출력\n",
    "for gen in generated_result.generations:\n",
    "    print(gen[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a99eed",
   "metadata": {},
   "source": [
    "### 2개 이상의 변수를 템플릿 안에 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b1093",
   "metadata": {},
   "source": [
    "2개 이상의 변수를 적용하여 템플릿을 생성할 수 있습니다.\n",
    "\n",
    "이번에는 2개 이상의 변수(`input_variables`) 를 활용하여 템플릿 구성을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9e9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 템플릿 형식 정의\n",
    "template = '{area1} 와 {area2} 의 시차는 몇시간이야?'\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3533451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울과 파리의 시차는 8시간입니다. 서울이 파리보다 8시간 앞서 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행: run() \n",
    "print(llm_chain.run(area1='서울', area2='파리'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78aaa1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파리와 뉴욕의 시차는 일반적으로 6시간입니다. 파리가 뉴욕보다 6시간 앞서 있습니다. 예를 들어, 파리가 오전 9시라면 뉴욕은 오전 3시입니다.\n",
      "서울과 하와이의 시차는 서울이 하와이보다 19시간 빠릅니다. 예를 들어, 서울이 오전 9시라면 하와이는 전날 오후 2시입니다.\n",
      "켄버라와 베이징의 시차는 2시간입니다. 켄버라는 오스트레일리아의 수도로 UTC+10 시간대에 위치하고, 베이징은 중국의 수도로 UTC+8 시간대에 위치합니다.\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'area1': '파리', 'area2': '뉴욕'},\n",
    "    {'area1': '서울', 'area2': '하와이'},\n",
    "    {'area1': '켄버라', 'area2': '베이징'}\n",
    "]\n",
    "\n",
    "# 반복문으로 결과 출력\n",
    "result = llm_chain.apply(input_list)\n",
    "for res in result:\n",
    "    print(res['text'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef6054",
   "metadata": {},
   "source": [
    "## 스트리밍(streaming)\n",
    "\n",
    "스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\n",
    "\n",
    "다음과 같이 `streaming=True` 로 설정하고 스트리밍으로 답변을 받기 위한 `StreamingStdOutCallbackHandler()` 을 콜백으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14dfb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \n",
    "                 max_tokens=2048,             # 최대 토큰수\n",
    "                 model_name='gpt-3.5-turbo',  # 모델명\n",
    "                 streaming=True,              \n",
    "                 callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62d721f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 서울입니다."
     ]
    }
   ],
   "source": [
    "# 질의내용\n",
    "question = '대한민국의 수도는 뭐야?'\n",
    "\n",
    "# 스트리밍으로 답변 출력\n",
    "response = llm.predict(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
